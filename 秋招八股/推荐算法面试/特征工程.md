##### 1.为什么说，用物料的后验消费数据做召回存在"幸存者偏差"？能将这些消费数据用于排序吗？
- 一个物料的后验指标好，只能说明推荐系统把它推荐给了对的人，并不意味着把它推给任何人都能取得这么好的效果。
- 这些后验指标可以参与精排。毕竟交给精排模型的物料都已经通过了召回、粗排两环节的筛选，多多少少是和当前用户相关的，"幸存者偏差"的影响还不至于那么严重，它们之前的后验指标还是有参考意义。
##### 2.使用物料的后验数据做召回的缺点，以及如何缓解
- 会放大“马太效应”，对新物料不友好。后验指标好的物料会被排得更靠前，获得更多曝光与点击的机会，后验指标会更好，形成正向循环；而新物料的后验指标不好甚至没有，排名靠后而较少获得曝光机会，后验指标迟迟得不到改善，形成负向循环
- 常规的作法就是拿所有样本在特征F上的均值（Mean）或中位数（Median）代替新物料的对应特征F。更合理的做法是训练一个模型来预测缺失值，比如对于新物料，我们可以训练一个模型，利用物料的静态画像（比如分类、标签、品牌、价位）预测它的动态画像（CTR、平均观看时长、平均销售额等）
##### 3.什么是bias特征？举出bias特征的例子？
- 具体实践中，我们无法做到让所有候选物料在一个绝对公平的环境中供用户挑选，这也就意味着用户的选择并非完全出于他的兴趣爱好，用户点击的未必是他喜欢的，没点击的也不代表用户就一定不喜欢，这种不可避免地引入的不公平因素就叫作"偏差"（Bias）。
- 如位置偏差，会引发的用户兴趣与反馈之间的脱节。如物料年龄偏差，会使上传早的视频有足够长的时间来积累人气，所以后验指标更好，模型排名更高。
##### 4.对观看次数、观看时长这样的特征，如何做标准化？
- 像这种长尾分布的特征，直接统计出来的μ和σ都会被长尾数据带偏，从而计算出来的z-score区分度下降。解决方法就是对原始数据做开方、取对数等非线性变换，先将原来的长尾分布压缩成接近正态分布，再在变换后的数据调用公式进行z-score标准化，能够取得更好的效果。
##### 5.数据平滑与消偏
- 推荐系统中经常要计算各种比率作为特征，比如点击率、点赞率、购买率、复购率等。计算这些比率时，我们经常遇到的一个问题就是样本太少，导致计算结果不可信。比如计算一件商品，只被曝光了一次并被购买了，由此我们就说它的购买率是100%，从而认定它是爆款，应该大力推荐，显然这是站不住脚的。为克服小样本的负面影响，提高计算结果的置信水平，我们可以采用**威尔逊区间平滑**
##### 6.数据样本
- 样本不均衡
	- 正负样本不均衡
		- 负样本降采样or正样本重复采样
			- 以一定概率从全量负样本中选取一部分样本，将其余的样本直接丢弃。
			- 优点：
				- 这种方法简单易行，一方面可以减少样本存储和模型训练的压力，另一方面可以缓解正负样本不均衡问题。
			- 缺点：
				- 但负样本中其实也有很多有用的信息，直接丢弃实在可惜，特别是在小场景样本不足时。
				- 负样本欠采样在一定程度上破坏了训练和预测两阶段数据分布的一致性
		- Focal loss
	- 不同活跃度用户不均衡
		- 对高活用户降采样：减少高活用户的正负样本，从而使得不同活跃度用户的样本可以均衡。随机降采样的方法实现简单，但由于丢弃了一部分样本，可能会损失一些宝贵的数据信息。
		- 样本加权与Focal Loss：可以在损失函数中增加低活用户样本的权重，使得模型更关注它们。同样，可以利用Focal Loss实现自动调权。
		- 多领域学习：将高活与中低活用户单独建模，分别训练它们的样本。为了加快模型收敛，可以共享模型Embedding层和部分底层。
- 样本不置信
	- 爬虫问题
		- 通过爬虫可以快速形成大量的点击行为，这些显然不是真实用户的行为。把它们加入精排正样本，会造成严重的样本不置信问题。因此，需要在网络请求的入口处拦截掉爬虫。
	- 服务端伪曝光
		- 服务端发出一次网络请求，会下发多条数据给客户端，用户可能需要滚动屏幕才能浏览完毕。如果用户未浏览完毕，则有部分数据没有得到真正曝光，形成伪曝光。如果将没有真正曝光的样本也加入负样本，则会带来负样本的不置信。所以一般需要采用客户端上报的日志来构建样本，避免出现伪曝光问题。
	- 未完全曝光
		- 最后一次点击下面的数据不要
	- 快速曝光
		- 在瀑布流产品中，用户快速滚动屏幕，会在短时间内产生大量曝光未点击样本。用户可能没有对这些物品给予足够关注，但如果直接认为用户不感兴趣，而把它们当作负样本，会有一定的样本不置信问题。在沉浸式产品中，这个问题同样存在。怎么避免这个问题呢？可以设定一个曝光时间阈值，将低于阈值的曝光未点击从负样本中去除。
	- 完全没有正样本的用户
		- 如果用户只是为了签到，或者碰巧被消息推送唤醒，抑或是随便点开了App，那么可能没有正样本，全是负样本。此时，用户是否点击与推荐的物品是否符合兴趣关系不大，可以直接将负样本过滤掉。
- 在线离线样本不一致
	- 数据穿越和特征穿越
	- 离在线特征不一致
		- 在线侧使用的特征很多是通过离线侧定时产出，再加载到线上系统中的，这会导致线上特征切换延时问题。例如，当特征按照天的级别产出时，如果特征切换发生在早上4点，则早上0点到4点之间的线上特征仍然是前一天的老特征。但离线侧构建样本时，通常整天都使用新特征，这就会导致一定程度的离在线特征不一致问题。若要优化这个问题，则一般可以将线上预测时使用的所有特征直接落盘，这样就不需要离线拼接特征构造样本，但会增加推荐工程的资源开销。
	- 离在线数据分布不一致