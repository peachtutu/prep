##### 1.改进粗排有什么思路
- 对粗排模型的设计与改进，主要是从模型结构、目标函数、样本空间三个方面入手
- 模型结构
	- 粗排双塔与召回双塔的异同
		- 相同
			- 训练时，都需要用户塔、物料塔隔离、解耦建模。不允许使用Target Attention这样的交叉结构，也不允许使用"用户与当前物料在标签上的重合度"之类的交叉特征。
			- 部署时，得益于双塔解耦的结构，面对一次用户请求，用户向量都只需要生成一遍。而物料向量，都可以离线生成好，缓存起来，被不同的用户请求复用。
		- 不同
			- 部署时物料向量的存储方式
				- 由于召回的候选集是百万、千万这个量级，所以召回双塔在将离线生成众多的物料向量后，还要将这些向量喂入FAISS之类的向量数据库建立索引。由于粗排候选集至多只到万量级，因此粗排双塔在离线生成物料向量后，无需喂入FAISS建立索引，直接存入内存缓存起来，Item ID当"键"，物料向量当"值"。
			- 样本选择
				- 召回负样本的主力必须由"随机负采样"组成。
				- 粗排，可以和精排一样，拿"曝光未点击"当负样本
			- 损失函数的设计
				- 召回双塔主要使用Batch Sampled Softmax当损失函数，对第i个样本，In-Batch Sampled Softmax的目标是将被选中的概率最大
				- 粗排双塔中的正负样本都需要被用户实际反馈yi所约束，所以Loss就是每个样本上的Binary Cross-Entropy Loss（BCE）。另外，粗排中只需要与做点积，而不牵扯与Batch内的其他物料的运算。
			- 最终用户向量与物料向量的交互方式
				- 由于召回的线上服务要调用ANN快速搜索近邻，受ANN算法限制，召回双塔中的用户向量和物料向量只能用点积来实现交叉。
				- 粗排双塔在分别得到用户向量和物料向量之后，可以拿这两个向量做点积来计算用户与物料间的匹配度，也可以将这两个向量用DNN或者其他方式做交叉。
	- 如何改进
		- [[双塔的缺点]]
- 目标函数
	- 精排蒸馏粗排
		- 共同训练
			- ![[1709869428087.png]]
			- 缺点：
				- 联合训练的模型，既要包含粗排参数，又要包含精排参数，是一个异常庞大的模型。而且无法保证粗、精排两个目标在更新参数时不会相互干扰呢
				- 将粗、精排模型耦合一起，维护更新时，牵一发而动全身，不能灵活应对业务目标
		- 两阶段
			- ![[1709869572601.png]]
- 样本空间
	- 为了解决这个"样本选择偏差"，需要我们在被精排排在后面、没有曝光机会的那部分物料中，选择一部分作为粗排的负样本。
	- 精排排序后，选择若干头部物料组成一个集合，选择若干尾部物料组成一个集合。
	- 将top与bottom中的物料两两配对，再搭配上当前用户user，组成一系列三元组
	- pairwise建模
	- ![[1709870395105.png]]
	- 上边介绍的方法中，只在精排结果中划分了头部与尾部两个档位。也有作法，将精排结果划分成更多档位，任意前后两个档位中的物料，都可以两两组合，组成Pair，喂入Pairwise LTR Loss建模偏序关系。优点是更多档位对精排排序刻画得**更加细致**，粗排对精排的"品味"学习得更加充分。缺点是，考虑了未曝光物料的物料集非常庞大，**物料之间的两两组合就更多了**，所以只能在每个档位抽样一部分物料参与组对儿。