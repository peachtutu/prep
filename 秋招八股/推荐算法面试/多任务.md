##### 1.如果expert出现极化现象，如何处理
- 解决方式
	- gate中加入dropout，环节过拟合；BN，L2正则化，防止出现极值
	- 缩放，对进入softmax之前的logit进行缩放，比如常见的除以维度中最大的logit来归一化
	- 复杂化gate网络，比如增加网络层数
- 极化一定是不好吗？
	- 不一定
	- 任务特定性：如果某些专家确实比其他专家更适合处理特定任务，模型倾向于这个专家也是合理的
	- 简化模型：那说明有些冗余的专家，可以减少专家数，简化模型
##### 2.为什么不为每个目标单独建模？
- 首先，这么做太浪费资源。大厂的推荐模型本来就对内存、算力消耗巨大，而有时同时建模10个目标也不算罕见。如果每个目标单独建模，需要将内存、算力的消耗都乘上10，这笔预算恐怕很难批得下来。
- 其次，用户转化是一个链条，比如先点击，再加入购物车，最后购买。在这个链条越靠后的环节，价值越大，但是可用于训练的正样本也就越少。单独训练的话，恐怕对那些稀疏的Embedding都训练不好，误差一定会很大
##### 3.为什么不直接针对最终目标建模？比如直接建模购买率，没必要建模点击率？
- 以电商场景为例，要同时建模CTR、CVR和CTCVR三个目标
- 首先，用户最终**没有购买**，并不代表用户就**一定不喜欢**推荐结果，也很有可能是因为商品**价格太高**。如果只以提高CTCVR为唯一目标，APP推荐给这名用户的就都是在他消费能力之内的**中低端**商品。可能会暂时提高销售额，但是会带来两方面的危害：
	- 容易造成用户的审美疲劳，对用户的长期留存不利。
	- 也失去给用户"种草"的机会。万一哪一天，用户狠下心来想剁手，APP却推荐不出来高端商品，也就白白浪费了一次提高销售额的机会。
- 其次，如前所述，无论是否转化，用户的每次点击都有价值。在广告定价时，会针对CTR、CVR、CTCVR设计不同的计费模式。所以，三个概率都要建模，并且都要预估得尽量准确。
- 只建模CTCVR，可用数据少，训练不充分，误差比较大
##### 4.损失融合
- 加权
- 在设置各损失的权重时，主要考虑两点：
	- 不同目标的轻重缓急，重要目标的权重肯定要大一些。
	- 不同损失的数值范围。比如，优化CTR目标时使用**交叉熵**函数，而优化观看时长时使用**均方误差**，而且时长往往是几十到几百秒，导致时长损失往往要比CTR损失大上一到两个数量级。
		- 通过除以常数、开方、求对数的方式压缩时长的数值
		- 通过设置合理的损失权重，将时长损失拉到与CTR损失相同量级
##### 5.多个打分的融合
- 乘法融合
- ![[1709871481699.png]]
- 加法融合
- ![[1709871538107.png]]
- F函数的难点在于，模型给不同目标的打分，天然存在分布差异。比如由于样本中的点击比例要远高于转化比例，所以预估CVR的数值普遍要比预估CTCVR高。如果权重再设置得不好（调超参没那么容易），可能导致融合得分不正确地偏向CTR而忽略CTCVR
- 一种思路是将F设置成各目标的打分转化为排名
- ![[1709871625875.png]]