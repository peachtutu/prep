##### 1.如何解决过拟合
- 模型过于复杂
	- 降低模型复杂程度
	- L1正则化
		- 让参数变稀疏 -> L1正则项的解空间是菱形，目标函数更容易和L1正则项相交在坐标轴上
		- 假设参数服从Laplace分布
	- L2正则化
		- 让参数趋近于0 -> L2正则项的解空间是球型，目标函数更容易和L2正则项通常不会相交在坐标轴上
		- 假设参数服从正态分布
	- dropout
		- infer如何做
			- 缩放权重法（Scale Weights）：在训练阶段不对神经元的输出进行缩放，而在测试阶段将每个神经元的权重乘以保留概率 p。这样，测试时网络的结构与训练时一致，但每个神经元的输出变为其训练时期望值的缩放版本。
			- 缩放激活法（Scale Activations）：在训练阶段对被保留的神经元的输出乘以1/p，以保证训练阶段和测试阶段的输出期望一致。在测试阶段，直接使用全部的神经元，不进行任何随机丢弃。
	- early stop
		- 训练过程中随机失活一部分神经元，推理阶段不做失活处理
		- 所以导致训练和推理阶段的期望不同
			- 可以把训练阶段的输出结果除以(1-p)
			- 可以把推理阶段的输出结果乘以p
	- BN
		- 缺点：
			- 批量大小的依赖性。BN层的效果在很大程度上依赖于批量的大小。较小的批量大小会导致估计的均值和方差不稳定，影响模型训练和最终性能。这在资源受限或需要使用小批量数据进行训练的情况下尤其成问题。
			- 不适合动态变化的批量大小，在某些应用场景下，如序列数据处理或图像处理中的动态计算图，批量大小可能会动态变化。BN层需要固定的批量大小来计算均值和方差，这使得它难以适应这类变化。
			- 增加模型复杂度和计算开销，尽管BN可以加速训练过程，但它也增加了模型的复杂度和计算开销。每个BN层都需要额外的参数（均值和方差的缩放参数和偏移参数）以及在训练和推理时进行额外的计算。
			- 推理时的性能问题，BN在训练和推理阶段的行为是不同的。在推理时，使用的是整个训练集的均值和方差，而不是批量的均值和方差。这种差异可能会导致推理性能不稳定，特别是在训练数据和实际应用数据分布有较大差异的情况下。
		- 推理和训练是一样吗
			- 不一样，因为推理过程中可能是单个样本进行推理，方差和均值偏差加大，应该使用训练阶段累积的均值和方差
		- 如果推理是是batch呢
			- 也不可以用
			- 一致性：使用训练阶段的统计量可以保证模型的行为在推理时与训练时保持一致，避免因为批次大小或数据分布的变化影响模型的输出。
			- 稳定性：在推理时，模型应该是确定性的，即相同的输入应该得到相同的输出。使用训练时计算的统计量可以保证这一点，而如果使用推理时批次的统计量，不同批次的数据可能导致模型输出有微小的变化。
			- 效率：在推理时使用预计算的统计量可以提高效率，因为不需要再对每个批次的数据计算均值和方差。
		- CNN上如何做BN
			- Batch Normalization 主要针对每个通道的激活进行归一化。具体来说，假设我们有一个批次的图像数据，形状为 (N,C,H,W)，其中：
				- N 是批次大小（batch size）。
				- C 是通道数（对于 RGB 图像，C=3C = 3C=3）。
				- H 是图像高度。
				- W 是图像宽度。
			- Batch Normalization 的归一化过程在每个通道上独立进行。对于每个通道 c，BN 的操作如下
![[1719047126592.png]]
- 数据集过于简单
	- 数据增强
##### 2.BN和Dropout的顺序
- BN放在dropout前
- BN 是在 mini-batch 内对每个特征进行标准化。如果 Dropout 放在 BN 之前，那么在每个 mini-batch 中，Dropout 随机丢弃一些神经元会改变 mini-batch 的分布，从而影响 BN 的标准化效果。
##### 3.手撕BN
```
import torch
from torch import nn

class BN(nn.Module)：
	def __init__(self, num_features, momentum=0.01, eps=1e-5):
		super().__init__()
		self.running_mean = torch.zeros(num_features)
        self.running_var = torch.ones(num_features))
        self.num_features = num_features
        self.eps = eps
        self.momentum = momentum
        self.gamma = nn.Parameter(torch.ones(num_features))  
        self.beta = nn.Parameter(torch.zeros(num_features))

	def forward(self, x):
		if self.training:
			x_mean = x.mean(dim=0, keepdim=True)
            x_var = x.var(dim=0, keepdim=True, unbiased=False)
            self.running_mean = (1 - self.momentum) * x_mean + self.momentum * self.running_mean
            self.running_var = (1 - self.momentum) * x_var + self.momentum * self.running_var
            x_normalized = (x - x_mean) / np.sqrt(x_var+self.eps)
		else:
			x_normalized = (x - self.running_mean) / np.sqrt(self.running_var + self.eps)
		return self.gamma * x_normalized + self.beta
```
##### 4.手撕LN
```
import torch
from torch import nn

class LN(nn.Module)：
	def __init__(self, features, eps=1e-5):
		super().__init__()
		self.eps = eps
        # 对应LN中需要更新的beta和gamma，采用pytorch文档中的初始化值
		self.gamma = nn.Parameter(torch.ones(features))  # 缩放参数
        self.beta = nn.Parameter(torch.zeros(features))  # 偏移参数

	def forward(self, x):
		x_mean = x.mean(dim=-1, keepdim=True)
        x_var = x.var(dim=-1, keepdim=True, unbiased=False)
        return self.gamma * (x - x_mean) / np.sqrt(x_var+self.eps) + self.beta
```
##### 5.梯度消失
- 原因：
	- 激活函数：使用某些激活函数（如Sigmoid或Tanh）时，当输入的绝对值较大或较小时，梯度会接近于0。因此，当网络很深时，这些微小的梯度会连乘，导致梯度在到达输入层时几乎消失。
	- 权重初始化：不恰当的权重初始化方法也会导致梯度消失。例如，如果权重初始化得太小，那么信号在每层传递时都会缩小，造成梯度消失。
	- 深度网络架构：在非常深的网络中，信息需要通过更多的层传播，这增加了梯度消失问题的风险
- 解决方案：
	- 使用ReLU
	- 合适的权重初始化：使用合适的权重初始化方法（如He初始化、Glorot/Xavier初始化）可以在训练初期防止梯度过小或过大，有助于缓解梯度消失问题。
	- 使用Batch Normalization：BN层可以通过调整每层输入的分布来减少内部协变量偏移，有助于保持梯度在合理范围内，从而缓解梯度消失问题。
	- ResNet
	- 梯度裁剪
	- 使用LSTM或GRU结构代替传统的RNN
##### 6.梯度爆炸
- 原因
	- 深度网络架构：在非常深的网络中，多个较大的权重值连乘可能导致梯度迅速增大，从而引发梯度爆炸。
	- 不恰当的权重初始化：如果权重初始化得太大，那么在网络的前几次迭代中，梯度可能会迅速增加，从而导致梯度爆炸。
- 解决方案
	- 梯度裁剪
	- 正则化
	- 改善权重初始化：使用合理的初始化策略（如He初始化、Glorot/Xavier初始化）可以在训练开始时防止梯度过大，有助于避免梯度爆炸。
	- 使用Batch Normalization：BN层可以规范化层输入的分布，有助于维持梯度在合理的范围内，间接地帮助控制梯度爆炸问题。
	- 小心调整学习率：使用较小的学习率可以减少每次权重更新的幅度，从而降低梯度爆炸的风险。


