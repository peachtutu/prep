##### 1.优缺点
- 优点
	- 算法简单、易于理解和实现。
	- 对于高维特征空间的数据集有较好的表现。
	- 对于缺失数据不敏感，能够处理部分缺失的样本（这是因为朴素贝叶斯算法基于特征之间的独立性假设，它假设每个特征对于分类的贡献是相互独立的。当数据中存在异常值时，它们可能会对某些特征的统计信息产生较大的影响，但由于特征之间的独立性假设，这种影响在计算条件概率时会被相对稳定的其他特征所抵消）
- 缺点：
	- 假设特征之间是相互独立的，这在现实数据中很难满足，特征之间相关性较大时，分类效果并不好
	- 对于特征空间中的连续变量，需要进行离散化处理，可能损失一些信息。
	- 模型过于简单
	- 当一个分类中的某个特征在训练集中没有出现时，会导致该特征的概率被估计为0，进而影响到整个模型的预测。尽管可以通过技术如拉普拉斯平滑来解决，但这是一个需要注意的问题。
##### 2.拉普拉斯平滑法
- 拉普拉斯平滑法是朴素贝叶斯中处理零概率问题的一种修正方式。在进行分类的时候，可能会出现某个属性在训练集中没有与某个类同时出现过的情况，如果直接基于朴素贝叶斯分类器的表达式进行计算的话就会出现零概率现象，而导致的分类错误或影响模型的稳定性。
- 为了避免其他属性所携带的信息被训练集中未出现过的属性值“抹去”，所以才使用拉普拉斯估计器进行修正
##### 3.朴素贝叶斯算法中如何处理连续特征和离散特征
- 连续特征处理：对于连续特征，朴素贝叶斯算法通常假设其服从高斯分布（正态分布）。为了处理连续特征，需要计算每个类别中该特征的均值和方差，并使用高斯分布的概率密度函数来估计给定特征值的概率。
- 离散特征处理：对于离散特征，朴素贝叶斯算法使用频数统计来估计每个特征值在每个类别下的概率。这可以通过计算在给定类别下某个特征值出现的频数，并除以该类别下所有样本的总数来实现。
