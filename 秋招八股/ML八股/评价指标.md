##### 1.评价指标
- 准确率：TP+TN/ALL
- 精确率：TP/TP+FP
- 召回率：TP/TP+FN
- F1-score：2*PreRecall/Pre+Recall
- ROC和AUC
	- X轴为假阳率，即所有负样本中分类错误的比率，FP/FP+TN
	- Y轴为真阳率，即所有正样本中分类正确的比率，等同于recall
	- AUC就是ROC的面积，越大越好，同时AUC还代表随机从正负样本集中抽取一个正样本，一个负样本，正样本的预测值大于负样本的概率，同时AUC也对正负样本比例不敏感，因此比PR曲线要好
	- AUC计算
method1
![[1709099274502.png]]
```
import numpy as np

def calculate_auc_func1(y_labels, y_scores):
    pos_sample_ids = [i for i in range(len(y_labels)) if y_labels[i] == 1]
    neg_sample_ids = [i for i in range(len(y_labels)) if y_labels[i] == 0]

    sum_indicator_value = 0
    for i in pos_sample_ids:
        for j in neg_sample_ids:
            if y_scores[i] > y_scores[j]:
                sum_indicator_value += 1
            elif y_scores[i] == y_scores[j]:
                sum_indicator_value += 0.5

    auc = sum_indicator_value/(len(pos_sample_ids) * len(neg_sample_ids))
    print('AUC calculated by function1 is {:.2f}'.format(auc))
    return auc
```
method2
![[1709099568214.png]]
```
import numpy as np

def calculate_auc_func2(y_labels, y_scores):
    samples = list(zip(y_scores, y_labels))
    rank = [(values2, values1) for values1, values2 in sorted(samples, key=lambda x:x[0])]
    pos_rank = [i+1 for i in range(len(rank)) if rank[i][0] == 1]
    pos_cnt = np.sum(y_labels == 1)
    neg_cnt = np.sum(y_labels == 0)
    auc = (np.sum(pos_rank) - pos_cnt*(pos_cnt+1)/2) / (pos_cnt*neg_cnt) # 这里并没有处理相同时选择avg，但在数据量较大时，可以忽略不记
    print('AUC calculated by function2 is {:.2f}'.format(auc))
    return auc
```
- GAUC：AUC有缺点，反应整体情况下
- NDCG
	- AUC不能反映位置这个信息
	- DCG
	![[1709160652490.png]]
		- K代表排序结果的长度
		- 代表第k个位置上的物料的贡献。如果用户未点击位置k上的物料，则=0；如果点击了，那么就是观看时长、销售金额等指标的函数（比如线性、开方、对数等）
		- 从分母上，我们可以看出，越靠后的位置，对物料价值打的折扣就越大。
	- IDCG
		- 即假设有一个完美的排序模型能够按各物料的真实贡献排序候选物料。这样一来，贡献最大的物料排在折扣最小的位置，按这种理想排序计算出的DCG就叫IDCG，也是DCG能够取得的最大值。
	- NDCG
	![[1709160796244.png]]
	- MAP
		- 每次只取前i个作为召回结果返回，将不同i下的Precision、Recall连接成曲线，然后计算这个Precision-Recall曲线下的面积，被称为Average Precision
		- AP只评估了单一一次召回结果，将多次召回的结果的AP取平均，就得到了MAP，就能用来衡量模型的整体召回性能
![[1709970160166.png]]
##### 2.如何处理样本不均衡
- 重新采样技术
	- 上采样（Over-sampling）少数类，下采样（Under-sampling）多数类
	- 修改类权重，为不同的类别分配不同的权重，使得模型在训练过程中更多地关注少数类。在损失函数中给予少数类更高的权重，可以强制模型更加重视这些类的正确分类。
	- 使用合适的评估指标，使用如F1分数、AUC等评估指标，这些指标能更好地反映模型对少数类的分类性能，而不是简单地使用准确率
	- 采用专门对样本不平衡更为鲁棒的算法，例如集成算法基于树的算法（如随机森林、梯度提升树）通常对样本不平衡不那么敏感
	- 人工合成数据，使用数据增强或生成对抗网络（GANs）等技术生成更多的少数类样本，以增强模型对少数类的学习能力。
	- Focal loss
##### 3.如何衡量特征之间的相关性
- 皮尔逊相关系数（Pearson Correlation Coefficient）
	- **适用条件**：用于衡量两个连续变量之间的线性关系。
![[1720363004623.png]]
	- **注意事项**：它只能检测线性关系，对非线性关系不敏感。
- 斯皮尔曼等级相关系数（Spearman's Rank Correlation Coefficient）
	- **适用条件**：用于衡量两个变量的单调关系，无论这种关系是否线性，适用于定序（有序类别）和连续变量。
	- 将数据转换为排名，然后计算排名之间的皮尔逊相关。
![[1720363080328.png]]
	- **优点**：对异常值不如皮尔逊相关系数敏感。
- 肯德尔等级相关系数（Kendall's Tau）
	- **适用条件**：用于衡量两个变量的关联程度，适用于有序分类变量。
	- 基于成对观测的一致性和不一致性。
![[1720363104066.png]]
	- **特点**：对小样本数据更加稳健。