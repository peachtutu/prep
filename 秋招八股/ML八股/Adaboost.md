##### 1.优缺点
- 优点
	- 高精度：AdaBoost 在处理复杂的分类问题时具有较高的准确性，它能够通过组合多个弱分类器来构建一个强分类器，提高整体的分类性能
	- 自适应调整：AdaBoost 在每一轮迭代中都会调整样本的权重，更加关注前一轮分类错误的样本，使得模型能够逐步适应困难样本，提高分类效果。
	- 不易过拟合：AdaBoost 在迭代过程中通过加权组合多个分类器，可以有效减少过拟合的风险，提高模型的泛化能力。
	- 简单易实现：AdaBoost 的基本原理简单，易于理解和实现。
- 缺点
	- 对异常值敏感：AdaBoost 对异常值敏感，异常值可能会对模型产生较大的影响，导致模型性能下降。
	- 训练时间较长，因为需要迭代多次来训练弱分类器和更新样本权重。
	- 数据不平衡问题：在数据不平衡的情况下，AdaBoost可能会过分关注少数类，导致模型偏向这些少数类，从而影响总体性能。
	- 选择弱分类器：虽然AdaBoost可以与任何分类器结合，但弱分类器的选择对最终模型的性能有很大影响。选择不当可能会导致模型性能不佳。
##### 2.Adaboost每轮训练都有错误分类的样本，但为何算法却能快速收敛？
- AdaBoost算法每轮训练后都会对样本权重进行调整。随着轮数的增加，被错误分类的样本的权重会逐渐增加。为了减少带权分类误差，后续的分类器会更加重视这些权重较高的样本，并将它们正确分类。

